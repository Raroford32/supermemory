import { describe, it, expect, vi, beforeEach, afterEach } from "vitest"
import {
  OpenRouterClient,
  createOpenRouterClient,
  cosineSimilarity,
  OPENROUTER_CONFIG,
  type OpenRouterConfig,
  type EmbeddingResponse,
  type ChatCompletionResponse,
} from "../openrouter"

// Mock fetch globally
const mockFetch = vi.fn()
global.fetch = mockFetch

describe("OpenRouter Configuration", () => {
  it("should have correct default configuration", () => {
    expect(OPENROUTER_CONFIG.baseUrl).toBe("https://openrouter.ai/api/v1")
    expect(OPENROUTER_CONFIG.embeddingModel).toBe("qwen/qwen3-embedding-8b")
    expect(OPENROUTER_CONFIG.embeddingDimensions).toBe(4096)
    expect(OPENROUTER_CONFIG.llmModel).toBe("openai/gpt-5.1")
    expect(OPENROUTER_CONFIG.defaultMaxTokens).toBe(4096)
    expect(OPENROUTER_CONFIG.defaultTemperature).toBe(0.7)
  })
})

describe("OpenRouterClient", () => {
  let client: OpenRouterClient

  beforeEach(() => {
    mockFetch.mockReset()
    client = new OpenRouterClient({
      apiKey: "test-api-key",
      verbose: false,
    })
  })

  afterEach(() => {
    vi.clearAllMocks()
  })

  describe("constructor", () => {
    it("should create client with default config", () => {
      const info = client.getModelInfo()
      expect(info.embeddingModel).toBe("qwen/qwen3-embedding-8b")
      expect(info.embeddingDimensions).toBe(4096)
      expect(info.llmModel).toBe("openai/gpt-5.1")
      expect(info.baseUrl).toBe("https://openrouter.ai/api/v1")
    })

    it("should create client with custom config", () => {
      const customClient = new OpenRouterClient({
        apiKey: "test-key",
        baseUrl: "https://custom.api.com",
        embeddingModel: "custom/embedding",
        llmModel: "custom/llm",
      })

      const info = customClient.getModelInfo()
      expect(info.embeddingModel).toBe("custom/embedding")
      expect(info.llmModel).toBe("custom/llm")
      expect(info.baseUrl).toBe("https://custom.api.com")
    })
  })

  describe("createEmbedding", () => {
    it("should create embedding for single input", async () => {
      const mockResponse: EmbeddingResponse = {
        data: [{ embedding: new Array(4096).fill(0.1), index: 0 }],
        model: "qwen/qwen3-embedding-8b",
        usage: { prompt_tokens: 10, total_tokens: 10 },
      }

      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve(mockResponse),
      })

      const result = await client.createEmbedding("test input")

      expect(mockFetch).toHaveBeenCalledWith(
        "https://openrouter.ai/api/v1/embeddings",
        expect.objectContaining({
          method: "POST",
          body: JSON.stringify({
            input: "test input",
            model: "qwen/qwen3-embedding-8b",
          }),
        })
      )

      expect(result.data[0].embedding.length).toBe(4096)
    })

    it("should create embeddings for batch input", async () => {
      const mockResponse: EmbeddingResponse = {
        data: [
          { embedding: new Array(4096).fill(0.1), index: 0 },
          { embedding: new Array(4096).fill(0.2), index: 1 },
        ],
        model: "qwen/qwen3-embedding-8b",
        usage: { prompt_tokens: 20, total_tokens: 20 },
      }

      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve(mockResponse),
      })

      const result = await client.createEmbedding(["input 1", "input 2"])

      expect(result.data.length).toBe(2)
    })

    it("should throw error on API failure", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: false,
        status: 401,
        text: () => Promise.resolve("Unauthorized"),
      })

      await expect(client.createEmbedding("test")).rejects.toThrow(
        "OpenRouter embedding failed: 401 - Unauthorized"
      )
    })
  })

  describe("embed", () => {
    it("should return single embedding vector", async () => {
      const embedding = new Array(4096).fill(0.1)
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: [{ embedding, index: 0 }],
          model: "qwen/qwen3-embedding-8b",
          usage: { prompt_tokens: 10, total_tokens: 10 },
        }),
      })

      const result = await client.embed("test text")

      expect(result.length).toBe(4096)
      expect(result[0]).toBe(0.1)
    })
  })

  describe("embedBatch", () => {
    it("should return multiple embedding vectors in order", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: [
            { embedding: new Array(4096).fill(0.2), index: 1 },
            { embedding: new Array(4096).fill(0.1), index: 0 },
          ],
          model: "qwen/qwen3-embedding-8b",
          usage: { prompt_tokens: 20, total_tokens: 20 },
        }),
      })

      const result = await client.embedBatch(["text1", "text2"])

      expect(result.length).toBe(2)
      expect(result[0][0]).toBe(0.1) // Sorted by index
      expect(result[1][0]).toBe(0.2)
    })
  })

  describe("createChatCompletion", () => {
    it("should create chat completion", async () => {
      const mockResponse: ChatCompletionResponse = {
        id: "chat-123",
        choices: [
          {
            index: 0,
            message: { role: "assistant", content: "Hello!" },
            finish_reason: "stop",
          },
        ],
        model: "openai/gpt-5.1",
        usage: { prompt_tokens: 10, completion_tokens: 5, total_tokens: 15 },
      }

      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve(mockResponse),
      })

      const result = await client.createChatCompletion({
        messages: [{ role: "user", content: "Hello" }],
      })

      expect(mockFetch).toHaveBeenCalledWith(
        "https://openrouter.ai/api/v1/chat/completions",
        expect.objectContaining({
          method: "POST",
          body: expect.stringContaining('"model":"openai/gpt-5.1"'),
        })
      )

      expect(result.choices[0].message.content).toBe("Hello!")
    })

    it("should use custom model when specified", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          id: "chat-123",
          choices: [{ index: 0, message: { role: "assistant", content: "Hi" }, finish_reason: "stop" }],
          model: "custom/model",
          usage: { prompt_tokens: 10, completion_tokens: 5, total_tokens: 15 },
        }),
      })

      await client.createChatCompletion({
        messages: [{ role: "user", content: "Hello" }],
        model: "custom/model",
      })

      expect(mockFetch).toHaveBeenCalledWith(
        expect.any(String),
        expect.objectContaining({
          body: expect.stringContaining('"model":"custom/model"'),
        })
      )
    })

    it("should throw error on API failure", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: false,
        status: 500,
        text: () => Promise.resolve("Internal Server Error"),
      })

      await expect(
        client.createChatCompletion({
          messages: [{ role: "user", content: "Hello" }],
        })
      ).rejects.toThrow("OpenRouter chat completion failed: 500")
    })
  })

  describe("chat", () => {
    it("should send simple chat message", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          id: "chat-123",
          choices: [{ index: 0, message: { role: "assistant", content: "Response" }, finish_reason: "stop" }],
          model: "openai/gpt-5.1",
          usage: { prompt_tokens: 10, completion_tokens: 5, total_tokens: 15 },
        }),
      })

      const result = await client.chat("Hello")

      expect(result).toBe("Response")
    })

    it("should include system prompt when provided", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          id: "chat-123",
          choices: [{ index: 0, message: { role: "assistant", content: "Response" }, finish_reason: "stop" }],
          model: "openai/gpt-5.1",
          usage: { prompt_tokens: 20, completion_tokens: 5, total_tokens: 25 },
        }),
      })

      await client.chat("Hello", { systemPrompt: "You are helpful" })

      expect(mockFetch).toHaveBeenCalledWith(
        expect.any(String),
        expect.objectContaining({
          body: expect.stringContaining('"role":"system"'),
        })
      )
    })
  })

  describe("analyze", () => {
    beforeEach(() => {
      mockFetch.mockResolvedValue({
        ok: true,
        json: () => Promise.resolve({
          id: "chat-123",
          choices: [{ index: 0, message: { role: "assistant", content: "Analysis result" }, finish_reason: "stop" }],
          model: "openai/gpt-5.1",
          usage: { prompt_tokens: 100, completion_tokens: 50, total_tokens: 150 },
        }),
      })
    })

    it("should analyze for invariants", async () => {
      const result = await client.analyze("contract Test {}", "invariant")
      expect(result).toBe("Analysis result")
    })

    it("should analyze for vulnerabilities", async () => {
      const result = await client.analyze("contract Test {}", "vulnerability")
      expect(result).toBe("Analysis result")
    })

    it("should analyze for exploits", async () => {
      const result = await client.analyze("contract Test {}", "exploit")
      expect(result).toBe("Analysis result")
    })

    it("should analyze for summary", async () => {
      const result = await client.analyze("contract Test {}", "summary")
      expect(result).toBe("Analysis result")
    })

    it("should use custom prompt", async () => {
      const result = await client.analyze("contract Test {}", "custom", "Custom analysis prompt")
      expect(result).toBe("Analysis result")
    })
  })

  describe("generateExploitTest", () => {
    it("should generate Foundry test code", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          id: "chat-123",
          choices: [{ index: 0, message: { role: "assistant", content: "// SPDX-License-Identifier: MIT\ncontract Test {}" }, finish_reason: "stop" }],
          model: "openai/gpt-5.1",
          usage: { prompt_tokens: 100, completion_tokens: 200, total_tokens: 300 },
        }),
      })

      const result = await client.generateExploitTest({
        targetContract: "Pool",
        vulnerability: "Reentrancy",
        attackPath: ["Call deposit", "Trigger callback", "Call withdraw"],
        expectedProfit: 100000,
      })

      expect(result).toContain("SPDX-License-Identifier")
    })
  })

  describe("checkSimilarity", () => {
    it("should detect duplicate content", async () => {
      // Mock embedding response
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: [{ embedding: [1, 0, 0, 0], index: 0 }],
          model: "qwen/qwen3-embedding-8b",
          usage: { prompt_tokens: 10, total_tokens: 10 },
        }),
      })

      const existingEmbeddings = [
        { id: "existing-1", embedding: [1, 0, 0, 0] }, // Same vector - similarity = 1
        { id: "existing-2", embedding: [0, 1, 0, 0] }, // Orthogonal - similarity = 0
      ]

      const result = await client.checkSimilarity("test content", existingEmbeddings, 0.9)

      expect(result.isDuplicate).toBe(true)
      expect(result.mostSimilarId).toBe("existing-1")
      expect(result.similarity).toBeCloseTo(1, 5)
    })

    it("should not flag novel content as duplicate", async () => {
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: [{ embedding: [0, 0, 1, 0], index: 0 }],
          model: "qwen/qwen3-embedding-8b",
          usage: { prompt_tokens: 10, total_tokens: 10 },
        }),
      })

      const existingEmbeddings = [
        { id: "existing-1", embedding: [1, 0, 0, 0] },
        { id: "existing-2", embedding: [0, 1, 0, 0] },
      ]

      const result = await client.checkSimilarity("novel content", existingEmbeddings, 0.9)

      expect(result.isDuplicate).toBe(false)
      expect(result.mostSimilarId).toBeNull()
    })
  })
})

describe("cosineSimilarity", () => {
  it("should calculate similarity of identical vectors", () => {
    const a = [1, 2, 3]
    const b = [1, 2, 3]
    expect(cosineSimilarity(a, b)).toBeCloseTo(1, 10)
  })

  it("should calculate similarity of orthogonal vectors", () => {
    const a = [1, 0, 0]
    const b = [0, 1, 0]
    expect(cosineSimilarity(a, b)).toBeCloseTo(0, 10)
  })

  it("should calculate similarity of opposite vectors", () => {
    const a = [1, 2, 3]
    const b = [-1, -2, -3]
    expect(cosineSimilarity(a, b)).toBeCloseTo(-1, 10)
  })

  it("should handle zero vectors", () => {
    const a = [0, 0, 0]
    const b = [1, 2, 3]
    expect(cosineSimilarity(a, b)).toBe(0)
  })

  it("should throw on dimension mismatch", () => {
    const a = [1, 2, 3]
    const b = [1, 2]
    expect(() => cosineSimilarity(a, b)).toThrow("Vector dimension mismatch")
  })

  it("should handle 4096-dimensional vectors (embedding size)", () => {
    const a = new Array(4096).fill(0).map((_, i) => Math.sin(i))
    const b = new Array(4096).fill(0).map((_, i) => Math.sin(i))
    expect(cosineSimilarity(a, b)).toBeCloseTo(1, 10)
  })
})

describe("createOpenRouterClient", () => {
  const originalEnv = process.env

  beforeEach(() => {
    process.env = { ...originalEnv }
  })

  afterEach(() => {
    process.env = originalEnv
  })

  it("should create client with provided API key", () => {
    const client = createOpenRouterClient({ apiKey: "test-key" })
    expect(client).toBeInstanceOf(OpenRouterClient)
  })

  it("should create client with environment variable", () => {
    process.env.OPENROUTER_API_KEY = "env-api-key"
    const client = createOpenRouterClient()
    expect(client).toBeInstanceOf(OpenRouterClient)
  })

  it("should throw error when no API key is available", () => {
    delete process.env.OPENROUTER_API_KEY
    expect(() => createOpenRouterClient()).toThrow("OpenRouter API key is required")
  })

  it("should prefer provided API key over environment variable", () => {
    process.env.OPENROUTER_API_KEY = "env-key"
    const client = createOpenRouterClient({ apiKey: "provided-key", verbose: true })
    // Client should be created with provided key
    expect(client).toBeInstanceOf(OpenRouterClient)
  })
})

describe("Headers", () => {
  it("should include required OpenRouter headers", async () => {
    const client = new OpenRouterClient({
      apiKey: "test-key",
      siteUrl: "https://mysite.com",
      siteName: "My App",
    })

    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        data: [{ embedding: [1, 2, 3], index: 0 }],
        model: "qwen/qwen3-embedding-8b",
        usage: { prompt_tokens: 10, total_tokens: 10 },
      }),
    })

    await client.embed("test")

    expect(mockFetch).toHaveBeenCalledWith(
      expect.any(String),
      expect.objectContaining({
        headers: expect.objectContaining({
          "Authorization": "Bearer test-key",
          "Content-Type": "application/json",
          "HTTP-Referer": "https://mysite.com",
          "X-Title": "My App",
        }),
      })
    )
  })
})
